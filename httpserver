#!/usr/bin/env python3
import argparse

import requests
import os, sys
import socket
import gzip
import shutil
from collections import Counter

DEFAULT_ORIGIN_SERVER_DOMAIN = "cs5700cdnorigin.ccs.neu.edu"
DEFAULT_ORIGIN_PORT = 8080
CACHED_FILES_LIST = "cached_files.txt"
DEFAULT_PORT = 40015
ORIGIN = "cs5700cdnorigin.ccs.neu.edu"
MAX_CACHE_SIZE_BYTES = 1000000 * 19  # 19MB of cache
MAX_CACHED_FILES = 1000
ZIPPED = True
ORIGIN_ONLY = False

#Final Submission Version

"""
Handles the client request. Either gets the html from source or cache
and returns the html to the client.

Runs with ./httpserver -p <port> -o <origin>

Responds to :
time ; wget http://[your server name]:[your port name]/[path to content]
"""

class HttpServer:
    def __init__(self, port, origin, display=False):
        self.port = port
        self.origin = origin

        self.current_folder = os.path.abspath(os.getcwd())
        self.cached_folder = self.current_folder + "/cached_files"
        self.current_size = os.path.getsize(self.current_folder)

        self.server_ip = socket.gethostbyname(socket.gethostname())
        self.cache = Cache(display=display)
        self.create_and_connect_socket()

        self.client_ip_ping_dict = {}

        self.request_count = 0

        self.display = display
        if self.display:
            print(
                "current folder size",
                self.current_size,
                "cache folder size",
                os.path.getsize(self.cached_folder),
            )

    def create_and_connect_socket(self):
        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            self.sock.bind((self.server_ip, self.port))
            print("Http Server connected and listening on port", self.port)
        except Exception as e:
            print("HTTP could not connect: ", e)
            self.sock.close()
            exit(0)

    def ping_client(self, dns_socket, client_ip):
        if self.display:
            print("Pinging client:", client_ip, "from", self.server_ip)

        try:
            # Ping the client 3 times
            ping_response = os.popen(f"ping -c 3 {client_ip}").read()
            # Parse the ping response for avg_rtt
            avg_rtt = float(ping_response.split("\n")[-2].split("=")[1].split("/")[1])

            # Communicate the ping rtt to the dns
            response_dns = f"PING_RTT {self.server_ip} {client_ip} {avg_rtt}".encode()
            dns_socket.send(response_dns)
        except Exception as e:
            print(
                f"Could not successfully ping client: {client_ip} from {socket.gethostname()}"
            )
            dns_socket.send(f"PING_RTT {self.server_ip} {client_ip} 999".encode())

    def receive_client_rq(self):
        # Reset the socket every 500 requests
        self.request_count += 1
        if self.request_count == 500:
            self.create_and_connect_socket()
            self.request_count = 0

        self.sock.listen(1)

        # Accept the socket connection from the client
        try:
            client_socket, client_ip = self.sock.accept()
        except Exception as e:
            print("Could not accept socket connection from client.")

        # Receive the request over the client socket with the client
        try:
            client_request = client_socket.recv(4096).decode("utf-8")
        except Exception as e:
            print("HTTP server could not receive client request, exception:", e)
            self.sock.close()

        if self.display:
            print("Client request:", client_request)

        if client_request.startswith("GET"):
            get_request_path = client_request.split("\r\n")[0]
            client_request_page = get_request_path.split(" ")[1]
            
        # Check for dns request
        elif client_request.startswith("PING"):  # /PING {ip}
            ip_to_ping = client_request.split()[1]
            self.ping_client(client_socket, ip_to_ping)
            return None, None
        
        else:
            print(
                "Unidentifiable request received from client ip:",
                client_ip,
                "Request:",
                client_request,
            )
            return None, None

        if client_request_page == "/grading/beacon":
            return "/grading/beacon", client_socket
            

        return client_request_page, client_socket

    def get_from_origin(self, client_request_page):
        complete_url = "http://" + ORIGIN + ":8080" + client_request_page
        response = requests.get(complete_url)
        if response.status_code == 200:
            header = f"HTTP/1.1 {response.status_code} OK\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
        else:
            header = f"HTTP/1.1 {response.status_code} ERROR\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
        response_content = header + response.content
        return response_content

    #####NOT ZIPPED
    def get_html(self, client_request_page):
        page_path = self.cached_folder + client_request_page
        # print("Client rq page", client_request_page, "page path", page_path)

        if page_path in self.cache.cached_files:
            if self.display == True:
                print("Found:", page_path, "is in the cache.")
            self.cache.cached_files[page_path] += 1
            return self.cache.get_file(page_path)
        else:
            if self.display == True:
                print("Could not find:", page_path, "in zipped cache. Querying the origin.")

            complete_url = "http://" + ORIGIN + ":8080" + client_request_page
            response = requests.get(complete_url)
            if response.status_code == 200:
                header = f"HTTP/1.1 200 OK\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
                response_content = header + response.content
                self.cache.add_to_cache(page_path, response_content)
                return response_content
            else:
                header = f"HTTP/1.1 {response.status_code} ERROR\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
                return header + response.content

    def get_html_from_zipped(self, client_request_page):
        """
        Get the html content from zipped cache files.
        """
        if ZIPPED:
            page_path = self.cached_folder + client_request_page + ".zip"

        if page_path in self.cache.cached_files:
            if self.display:
                print("Found:", page_path, "is in the cache.")
            self.cache.cached_files[page_path] += 1
            return self.cache.get_zipped_file(page_path)
        else:
            if self.display:
                print(
                    "Could not find:",
                    page_path,
                    "in zipped cache. Querying the origin.",
                )

            complete_url = (
                "http://"
                + ORIGIN
                + ":"
                + str(DEFAULT_ORIGIN_PORT)
                + "/"
                + client_request_page
            )
            response = requests.get(complete_url)
            if response.status_code == 200:
                header = f"HTTP/1.1 200 OK\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
                response_content = header + response.content
                self.cache.add_to_zipped_cache(page_path, response_content)
                return response_content
            else:
                header = f"HTTP/1.1 {response.status_code} ERROR\r\nContent-Length: {len(response.content)}\nContent-Type: text/html\r\n\r\n".encode()
                return header + response.content

    def send_html_response(self, client_rq, client_socket):
        """
        The html to send to the client socket handles the grading. 
        Any html returned is prepended with a 200 response header.
        """
        if client_rq == "/grading/beacon":
            response = "HTTP/1.1 204 No Content\r\n".encode("utf-8")
            client_socket.send(response)
        else:
            if ORIGIN_ONLY:
                response_content = self.get_from_origin(client_rq)
            elif ZIPPED:
                response_content = self.get_html_from_zipped(client_rq)
            else:
                response_content = self.get_html(client_rq)
            
            client_socket.send(response_content)

        client_socket.close()


"""
LFU cache 
The cached files are zipped and stored in a cached_files directory. Files are unzipped and returned to user.
A dictionary with frequency of calls is maintained in memory.
When maximum space allowed is used, the least frequeuntly queried file is removed
from the cache and the new query is added. 
"""

class Cache:
    def __init__(self, display=False) -> None:
        # {webpage1: {QUERY_FREQ: int}, webpage2: }
        self.cached_files = Counter()

        self.current_folder = os.path.abspath(os.getcwd())
        self.cached_folder = self.current_folder + "/cached_files"

        if os.path.exists(self.cached_folder):
            shutil.rmtree(self.cached_folder)
        os.makedirs(self.cached_folder)

        self.current_size = os.path.getsize(self.current_folder)
        self.display = display
        # print('curr folder', self.current_folder, 'curr folder size', self.current_size)

    def remove_least_freq_used(self):
        """
        Cache replacement to remove least frequently used url and update data structures.
        Removes the file from the cache, reduces the size, and removes from list of cached_files.
        """
        # Get least used file
        if self.display:
            print("All cached files freq\n:", self.cached_files.most_common())

        LFU_link = self.cached_files.most_common().pop()[0]
        if self.display:
            print(
                "Least frequently used file link: ",
                LFU_link,
                "file size:",
                os.path.getsize(LFU_link),
                "total size:",
                self.current_size,
            )

        # Decrease size used
        self.current_size -= os.path.getsize(LFU_link)

        # Remove the filename from the cache dict
        self.cached_files.pop(LFU_link)

        # Remove the file
        os.remove(LFU_link)

        if self.display:
            print("New size:", self.current_size, "files remaining:", self.cached_files)
            print("Removed", LFU_link, "from cache dict, size, and folder.")

    def add_to_zipped_cache(self, zip_filepath, response_content):
        """
        Cache replacement removes least freq used url and writes new file to the cache.
        Updates associated data structures and used file size.
        """
        if self.current_size > MAX_CACHE_SIZE_BYTES:
            self.remove_least_freq_used()

        # Zip and write the contents to the file
        with gzip.open(zip_filepath, "wb") as wfile:
            wfile.write(response_content)

        # Add to cache dict and current size
        self.current_size += os.path.getsize(zip_filepath)
        self.cached_files[zip_filepath] = 1

    def get_zipped_file(self, filepath):
        # Opens the zipped file, reads and returns the contents
        with gzip.open(filepath, "rb") as f:
            contents = f.read()

        return contents
    
    # NOT ZIPPED FUNCTIONS
    def add_to_cache(self, filepath, response_content):
        if self.current_size > MAX_CACHE_SIZE_BYTES:
            self.remove_least_freq_used()

        # Write the contents to the file
        with open(filepath, "wb") as wfile:
            wfile.write(response_content)

        # Add to cache dict and current size
        self.current_size += os.path.getsize(filepath)
        self.cached_files[filepath] = 1

    def get_file(self, filepath):
        # for cache run when that are not zipped
        with open(filepath, "rb") as f:
            contents = f.read()

        return contents


def main():
    parser = argparse.ArgumentParser(description="Parser for dnsserver args")
    parser.add_argument(
        "-p",
        "--port",
        metavar="",
        type=int,
        help="Port that the http server will bind to",
    )
    parser.add_argument(
        "-o",
        "--origin",
        metavar="",
        help="origin server containing all html files, http servers will contact this server if "
             "they do not have the requested page cached"
    )

    # -----------------------------------------------------------------------------------------------------
    # optional args
    parser.add_argument(
        "-d",
        "--default",
        metavar="",
        help="optional, exclusive arg, if not None default port and name values and displays print statements",
    )
    parser.add_argument(
        "-s",
        "--display",
        metavar="",
        help="optional arg, if not None displays print statements",
    )
    args = parser.parse_args()

    if args.default is not None:
        args.port = DEFAULT_PORT
        args.origin = DEFAULT_ORIGIN_SERVER_DOMAIN
    else:
        if args.port is None:
            print("Missing port (-p) arguments")
            print("EXITING httpserver program")
            exit(0)
        elif args.origin is None:
            print("Missing port (-o) arguments")
            print("EXITING httpserver program")
            exit(0)

    if args.display is not None:
        args.display = True
    else:
        args.display = False

    httpserver = HttpServer(args.port, args.origin, display=args.display)

    while True:
        try:
            client_rq, client_socket = httpserver.receive_client_rq()
            if client_rq is None or client_socket is None:
                # request from the dns
                continue
            else:
                httpserver.send_html_response(client_rq, client_socket)
        except KeyboardInterrupt:
            httpserver.sock.close()


main()
